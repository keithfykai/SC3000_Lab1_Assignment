{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yue-zhongqi/cartpole_colab/blob/main/cartpole.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZauhjPSfX7pI"
   },
   "source": [
    "# Tutorial and Sample Code for Balancing a Pole on a Cart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBiYOoesYMvr"
   },
   "source": [
    "## Installing dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PbgnVwZmX5uW",
    "outputId": "7dcfe5ac-b419-4d5d-8305-1ba3c1240df3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: apt-get\n",
      "Requirement already satisfied: gym in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (0.26.2)\n",
      "Requirement already satisfied: pyvirtualdisplay in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (3.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from gym) (1.24.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from gym) (4.11.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from gym) (2.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gym) (3.8.0)\n",
      "zsh:1: command not found: apt-get\n",
      "zsh:1: no matches found: gym[classic_control]\n",
      "zsh:1: command not found: apt-get\n",
      "zsh:1: command not found: apt-get\n",
      "Requirement already satisfied: setuptools in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (69.1.1)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-69.2.0-py3-none-any.whl (821 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.5/821.5 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 69.1.1\n",
      "    Uninstalling setuptools-69.1.1:\n",
      "      Successfully uninstalled setuptools-69.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed setuptools-69.2.0\n",
      "Requirement already satisfied: ez_setup in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (0.9)\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y xvfb python-opengl\n",
    "!pip install gym pyvirtualdisplay\n",
    "!apt-get install -y xvfb python-opengl ffmpeg\n",
    "!pip install gym[classic_control]\n",
    "!apt-get update\n",
    "!apt-get install cmake\n",
    "!pip install --upgrade setuptools\n",
    "!pip install ez_setup\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp39-cp39-macosx_10_15_x86_64.whl (259.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.24.4)\n",
      "Collecting h5py>=3.10.0\n",
      "  Downloading h5py-3.10.0-cp39-cp39-macosx_10_9_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.36.0-cp39-cp39-macosx_10_14_x86_64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-24.3.7-py2.py3-none-any.whl (26 kB)\n",
      "Collecting ml-dtypes~=0.3.1\n",
      "  Downloading ml_dtypes-0.3.2-cp39-cp39-macosx_10_9_universal2.whl (389 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.8/389.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.9.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting keras>=3.0.0\n",
      "  Downloading keras-3.0.5-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.17,>=2.16\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (69.2.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-macosx_10_9_x86_64.whl (24.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.62.1-cp39-cp39-macosx_10_10_universal2.whl (10.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.28.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting rich\n",
      "  Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting namex\n",
      "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Collecting dm-tree\n",
      "  Downloading dm_tree-0.1.8-cp39-cp39-macosx_10_9_x86_64.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.4/115.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.3.4)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, dm-tree, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, pygments, protobuf, opt-einsum, ml-dtypes, mdurl, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, markdown-it-py, rich, keras, tensorflow\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.7.0\n",
      "    Uninstalling h5py-3.7.0:\n",
      "      Successfully uninstalled h5py-3.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-2.1.0 astunparse-1.6.3 dm-tree-0.1.8 flatbuffers-24.3.7 gast-0.5.4 google-pasta-0.2.0 grpcio-1.62.1 h5py-3.10.0 keras-3.0.5 libclang-16.0.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.7 opt-einsum-3.3.0 protobuf-4.25.3 pygments-2.17.2 rich-13.7.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.36.0 termcolor-2.4.0\n"
     ]
    }
   ],
   "source": [
    "# Added in\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/keith/opt/anaconda3/lib/python3.9/site-packages (1.24.4)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwKbYeTgbaTA"
   },
   "source": [
    "## Importing dependencies and define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6KpgCLGYWmj"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import logger as gymlogger\n",
    "from gym.wrappers import RecordVideo\n",
    "gymlogger.set_level(40) #error only\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "def show_video():\n",
    "  mp4list = glob.glob('video/*.mp4')\n",
    "  if len(mp4list) > 0:\n",
    "    mp4 = mp4list[0]\n",
    "    video = io.open(mp4, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "  else: \n",
    "    print(\"Could not find video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehbqP9CXbmo7"
   },
   "source": [
    "## Tutorial: Loading CartPole environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Go12dH4qbwBy"
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XZ9g3xrcAXE"
   },
   "source": [
    "We can check the action and observation space of this environment. Discrete(2) means that there are two valid discrete actions: 0 & 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ytxvVmLdcRyw",
    "outputId": "1ce07099-492b-4126-a792-8ff12d79c2db"
   },
   "outputs": [],
   "source": [
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVXGWi_Ncfg-"
   },
   "source": [
    "The observation space is given below. The first two arrays define the min and max values of the 4 observed values, corresponding to cart position, velocity and pole angle, angular velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DyqHr9I5cdkX",
    "outputId": "369a0733-e7c0-4bca-b427-5e1c603ff074"
   },
   "outputs": [],
   "source": [
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFOdaU2Gdyg0"
   },
   "source": [
    "We call each round of the pole-balancing game an \"episode\". At the start of each episode, make sure the environment is reset, which chooses a random initial state, e.g., pole slightly tilted to the right. This initialization can be achieved by the code below, which returns the observation of the initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VMr6qAqxdOsm",
    "outputId": "0e35ee3b-15d0-4e1f-926c-194a5a43f830"
   },
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "print(\"Initial observations:\", observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnG2QdfbeZrI"
   },
   "source": [
    "For the CartPole environment, there are two possible actions: 0 for pushing to the left and 1 for pushing to the right. For example, we can push the cart to the left using code below, which returns the new observation, the current reward, an indicator of whether the game ends, and some additional information (not used in this project). For CartPole, the game ends when the pole is significantly tilted or you manage to balance the pole for 500 steps. You get exactly 1 reward for each step before the game ends (i.e., max cumulative reward is 500)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MmfMDvyYdWGk",
    "outputId": "fa12ffd8-6707-4cbc-fb86-aef8484d5d17"
   },
   "outputs": [],
   "source": [
    "observation, reward, done, info = env.step(0)[:4]\n",
    "print(\"New observations after choosing action 0:\", observation)\n",
    "print(\"Reward for this step:\", reward)\n",
    "print(\"Is this round done?\", done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tj0zCh59fhBb"
   },
   "source": [
    "Now we can play a full round of the game using a naive strategy (always choosing action 0), and show the cumulative reward in the round. Note that reward returned by env.step(*) corresponds to the reward for current step. So we have to accumulate the reward for each step. Clearly, the naive strategy performs poorly by surviving only a dozen of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AVucQVRwf6Jm",
    "outputId": "72f0b7d5-7cb5-4e37-da3d-997c1bfb4641"
   },
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "cumulative_reward = 0\n",
    "done = False\n",
    "while not done:\n",
    "    observation, reward, done, info = env.step(0)[:4]\n",
    "    cumulative_reward += reward\n",
    "print(\"Cumulative reward for this round:\", cumulative_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oIzK9SzhlWN"
   },
   "source": [
    "## Task 1: Development of an RL agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cc6_e5c_huiq"
   },
   "source": [
    "An example of a naive agent is given below, which randomly chooses an action regardless of the observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hk-M4QEfh6l5"
   },
   "outputs": [],
   "source": [
    "def rand_policy_agent(observation):\n",
    "    return random.randint(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAi7KKwNiegR"
   },
   "source": [
    "For Task 1, we can show the observation and chosen action below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae2ia-vUiNKJ",
    "outputId": "22c614ca-5ba0-43d3-d27a-d79073b5d04e"
   },
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "action = rand_policy_agent(observation)\n",
    "print(\"Observation:\", observation)\n",
    "print(\"Chosen action:\", action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XtIQ0Rti1gm"
   },
   "source": [
    "## Task 2: Demonstrate the effectiveness of the RL agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djBEShf0kGI4"
   },
   "source": [
    "For this task, use the agent developed in Task 1 to play the game for 100 episodes (refer to tutorial for how to play a round), record the cumulative reward for each round, and plot the reward for each round. A sample plotting code is given below. Note that you must include code to play for 100 episodes and use the code to obtain round_results for plotting. DO NOT record the round results in advance and paste the results to the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "RZrCKywQi6CE",
    "outputId": "e304ecc5-14b6-4cf1-831b-dcb42eb46351"
   },
   "outputs": [],
   "source": [
    "episode_results = np.random.randint(150, 250, size=100)\n",
    "plt.plot(episode_results)\n",
    "plt.title('Cumulative reward for each episode')\n",
    "plt.ylabel('Cumulative reward')\n",
    "plt.xlabel('episode')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XndSYH7wlvn7"
   },
   "source": [
    "Print the average reward over the 100 episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pOiOp9OYlo5Y",
    "outputId": "7a02ba7b-ff17-41f2-aa7f-eb50d49a83fd"
   },
   "outputs": [],
   "source": [
    "print(\"Average cumulative reward:\", episode_results.mean())\n",
    "print(\"Is my agent good enough?\", episode_results.mean() > 195)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yg0DCT38lFA6"
   },
   "source": [
    "## Task 3: Render one episode played by the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vx1awMr9lc_w"
   },
   "source": [
    "Plug your agent to the code below to obtain rendered result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "LYyavfbIa47D",
    "outputId": "10c2f1e7-f3b9-4975-ed25-7c380966a56c"
   },
   "outputs": [],
   "source": [
    "env = RecordVideo(gym.make(\"CartPole-v1\"), \"./video\")\n",
    "observation = env.reset()\n",
    "while True:\n",
    "    env.render()\n",
    "    #your agent goes here\n",
    "    action = rand_policy_agent(observation)\n",
    "    observation, reward, done, info = env.step(action)[:4]\n",
    "    if done: \n",
    "      break;    \n",
    "env.close()\n",
    "show_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNczA+lJQOKjOo4XtzYjWQc",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
